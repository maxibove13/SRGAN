{"cells":[{"cell_type":"markdown","metadata":{"id":"y3Oa6cU4xMDN"},"source":["# Super Resolution GAN (SRGAN) training"]},{"cell_type":"markdown","metadata":{"id":"UrC-T3yWxMDV"},"source":["### Mount drive if in colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc_FXsfVxMDX"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Navigate to repository\n","%cd /content/drive/MyDrive/Github/SRGAN\n","\n","!pip install albumentations==0.4.6"]},{"cell_type":"markdown","metadata":{"id":"42ipoOxnxMDa"},"source":["### Import needed modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dYPb1QIxMDb"},"outputs":[],"source":["import config\n","import torch\n","from torch import nn\n","# Optimization algorithms\n","import torch.optim as optim\n","# Dataset manager\n","from torch.utils.data import DataLoader\n","\n","from torchvision.models import vgg19"]},{"cell_type":"markdown","metadata":{"id":"osNBARtpxMDc"},"source":["## 0. Define and prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bffE2TXsxMDd"},"outputs":[],"source":["from dataset import MyImageFolder\n","\n","dataset = MyImageFolder(root_dir=\"new_data\")\n","print(f\"{len(dataset)} samples in dir {dataset.root_dir}/{dataset.class_names[0]}\")"]},{"cell_type":"markdown","metadata":{"id":"CB3dlJtBxMDf"},"source":["## 1. Create model"]},{"cell_type":"markdown","metadata":{"id":"XVBJ5ixmxMDq"},"source":["### Initialize Generator and Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OaqBaXARxMDr"},"outputs":[],"source":["from model import Generator, Discriminator\n","\n","gen = Generator(in_channels=3).to(config.DEVICE)\n","disc = Discriminator(in_channels=3).to(config.DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"IvdhMNQuxMDr"},"source":["## 2. Loss and optimizer"]},{"cell_type":"markdown","metadata":{"id":"bFmJKuvyxMDs"},"source":["### Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VxZ-79BxMDs"},"outputs":[],"source":["class VGGLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.vgg = vgg19(pretrained=True).features[:36].eval().to(config.DEVICE)\n","        self.loss = nn.MSELoss()\n","\n","        for param in self.vgg.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, input, target):\n","        vgg_input_features = self.vgg(input)\n","        vgg_target_features = self.vgg(input)\n","        return self.loss(vgg_input_features, vgg_target_features)\n","\n","bce = nn.BCEWithLogitsLoss()\n","vgg_loss_fun = VGGLoss()\n","mse = nn.MSELoss()"]},{"cell_type":"markdown","metadata":{"id":"CgMxkPJ6xMDt"},"source":["### Optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7MxdstcxMDt"},"outputs":[],"source":["opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.9, 0.999))\n","opt_disc = optim.Adam(disc.parameters(), lr=config.LEARNING_RATE, betas=(0.9, 0.999))"]},{"cell_type":"markdown","metadata":{"id":"WnPpRqrnxMDu"},"source":["## 3. Training"]},{"cell_type":"markdown","metadata":{"id":"JhXfglv1xMDv"},"source":["### Train discriminator and generator functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcmhXhhkxMDv"},"outputs":[],"source":["### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","def train_discriminator(D, opt, fake, high_res, bce):\n","\n","    # Reset gradients to zero\n","    opt.zero_grad()\n","\n","    # Train on real data\n","    pred_real = D(high_res)\n","    loss_real = bce(pred_real, torch.ones_like(pred_real) - 0.1 * torch.rand_like(pred_real))\n","\n","    # Train on fake data\n","    pred_fake = D(fake.detach())\n","    loss_fake = bce(pred_fake, torch.zeros_like(pred_fake))\n","\n","    loss = loss_real + loss_fake\n","\n","    # Backward pass\n","    loss.backward()\n","    # Update weights\n","    opt.step()\n","\n","    return loss\n","\n","### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","def train_generator(D, opt, fake, high_res, vgg_loss, mse):\n","\n","    # Reset gradients to zero\n","    opt.zero_grad()\n","\n","    pred_fake = D(fake)\n","\n","    adv_loss = 1e-3 * bce(pred_fake, torch.ones_like(pred_fake))\n","    vgg_loss = 0.006 * vgg_loss(fake, high_res)\n","    mse_loss = mse(fake, high_res)\n","\n","    loss = adv_loss + vgg_loss + mse_loss\n","\n","    # Backward pass\n","    loss.backward()\n","    # Update weights\n","    opt.step()\n","\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"XRUeIpZ-xMDw"},"source":["### Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZA7rsMo0xMDw"},"outputs":[],"source":["loader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=config.NUM_WORKERS)"]},{"cell_type":"markdown","metadata":{"id":"rvLjCHl2xMDw"},"source":["### Load last checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9JCxvtbVxMDx"},"outputs":[],"source":["from utils import load_checkpoint\n","\n","if config.LOAD_MODEL:\n","    load_checkpoint(\n","        config.CHECKPOINT_GEN,\n","        gen,\n","        opt_gen,\n","        config.LEARNING_RATE\n","    )\n","    load_checkpoint(\n","        config.CHECKPOINT_DISC, disc, opt_disc, config.LEARNING_RATE\n","    )"]},{"cell_type":"markdown","metadata":{"id":"_uUvJJvlxMDx"},"source":["### Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eX8P92zNxMDy"},"outputs":[],"source":["from utils import plot_examples, save_checkpoint, plot_loss\n","from time import process_time\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from IPython import display\n","from matplotlib.ticker import MaxNLocator\n","\n","print(f\"SRGAN training: \\n\")\n","print(f\" Total training samples: {len(dataset)}\\n Number of epochs: {config.NUM_EPOCHS}\\n Mini batch size: {config.BATCH_SIZE}\\n Number of batches: {len(loader)}\\n Learning rate: {config.LEARNING_RATE}\\n\")\n","\n","\n","loss_disc = []\n","loss_gen = []\n","\n","# Start the stopwatch\n","t0 = process_time()\n","\n","fig, ax = plt.subplots(figsize=(10,6), dpi= 80)\n","\n","for epoch in range(config.NUM_EPOCHS):\n","    for idx, (low_res, high_res) in enumerate(loader):\n","\n","        # Send images to device\n","        high_res = high_res.to(config.DEVICE)\n","        low_res = low_res.to(config.DEVICE)\n","\n","        # Generate fake (high_res) image from low_res\n","        fake = gen(low_res)\n","\n","        loss_disc_e = train_discriminator(disc, opt_disc, fake, high_res, bce)\n","        loss_gen_e = train_generator(disc, opt_gen, fake, high_res, vgg_loss_fun, mse)\n","\n","        # At the end of every epoch\n","        if idx == config.BATCH_SIZE-1:\n","\n","\n","            # Plot gen and disc loss\n","            # Append current epoch loss to list of losses\n","            loss_disc.append(float(loss_disc_e.detach().cpu()))\n","            loss_gen.append(float(loss_gen_e.detach().cpu()))\n","\n","            x = np.arange(0, epoch+1)\n","            print(x, loss_disc, loss_gen)\n","            ax.plot(x, loss_disc, label='Discriminator loss', marker='o', color='b')\n","            ax.plot(x, loss_gen, label='Generator loss', marker='o', color='r')\n","            ax.set_title('Evolution of losses through epochs')\n","            ax.set(xlabel='epochs')\n","            ax.set(ylabel='loss')\n","            # ax.set_xlim(left=0, right=config.NUM_EPOCHS-1)\n","            ax.grid()\n","            if epoch == 0:\n","              ax.legend(loc='upper right')\n","            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n","\n","            display.clear_output(wait=True)\n","            print(f\"SRGAN training: \\n\")\n","            print(f\" Total training samples: {len(dataset)}\\n Number of epochs: {config.NUM_EPOCHS}\\n Mini batch size: {config.BATCH_SIZE}\\n Number of batches: {len(loader)}\\n Learning rate: {config.LEARNING_RATE}\\n\")\n","            # Display current figure\n","            display.display(fig)\n","            # Pause execution 0.1s\n","            time.sleep(0.1)\n","            plt.close()\n","            ax.grid()\n","            \n","            # Print progress every epoch\n","            print( \n","                f\"Epoch [{epoch}/{config.NUM_EPOCHS} - \"\n","                f\"Loss D: {loss_disc_e:.4f}, Loss G: {loss_gen_e:.4f}]\"\n","                )\n","\n","    if config.SAVE_MODEL:\n","        save_checkpoint(gen, opt_gen, filename=config.CHECKPOINT_GEN)\n","        save_checkpoint(disc, opt_disc, filename=config.CHECKPOINT_DISC)\n","\n","# Stop the stopwatch\n","t1 = process_time()\n","print(f\"Elapsed time: {t1-t0}\")\n","\n","plt.savefig(\"loss_evol.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTHB8h5BZW1w"},"outputs":[],"source":["import os\n","\n","test_images = next(os.walk(\"datasets/testing/\"))[2]"]},{"cell_type":"markdown","metadata":{"id":"7i5BuFpHWWLX"},"source":["## Test generator with pretrained net (checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_37fqIEquqmF"},"outputs":[],"source":["import os\n","\n","from utils import load_checkpoint, plot_examples\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","testing = True # If not testing: validation\n","r = 3 # Zoom factor\n","\n","# Initialize SRGAN Generator\n","gen = Generator(in_channels=3).to(config.DEVICE)\n","# Define optimizer for Generator\n","opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.9, 0.999))\n","\n","# Load checkpoint (w&b of specified training)\n","if config.LOAD_MODEL:\n","    load_checkpoint(\n","        config.CHECKPOINT_GEN,\n","        gen,\n","        opt_gen,\n","        config.LEARNING_RATE\n","    )\n","    # load_checkpoint(\n","    #     config.CHECKPOINT_DISC, disc, opt_disc, config.LEARNING_RATE\n","    # )\n","\n","# Get all images in testing folder\n","\n","# Test generator in all images in testing folder\n","plot_examples(\"datasets/testing/\", gen, 0)\n","\n","# Get list of generated super resolution images\n","sr_images = next(os.walk(\"datasets/testing/sr/\"))[2]\n","\n","# Get list of testing images\n","test_images = next(os.walk(\"datasets/testing/\"))[2]\n","\n","# If validating, get hr images\n","if not testing:\n","  hr_images = next(os.walk(\"new_data/hr/\"))[2:][0]\n","\n","# Loop through all test_images\n","for idx, im in enumerate(test_images):\n","    # Read lr, sr and hr images\n","    lr_im = mpimg.imread(f\"datasets/testing/{im}\")\n","    sr_im = mpimg.imread(f\"datasets/testing/sr/{sr_images[idx]}\")\n","    if not testing:\n","      hr_im = mpimg.imread(f\"new_data/hr/{hr_images[idx]}\")\n","\n","    # Get new widths and heights given zoom in factor r\n","    w0 = sr_im.shape[0]//2-sr_im.shape[0]//r\n","    w1 = sr_im.shape[0]//2+sr_im.shape[0]//r\n","    h1 = sr_im.shape[1]//2-sr_im.shape[1]//r\n","    h2 = sr_im.shape[1]//2+sr_im.shape[1]//r\n","    w0_l = lr_im.shape[0]//2-lr_im.shape[0]//r\n","    w1_l = lr_im.shape[0]//2+lr_im.shape[0]//r\n","    h1_l = lr_im.shape[1]//2-lr_im.shape[1]//r\n","    h2_l = lr_im.shape[1]//2+lr_im.shape[1]//r\n","\n","    # Crop images and define titles for comparison figure\n","    ims = [lr_im[w0_l:w1_l, h1_l:h2_l, :], sr_im[w0:w1, h1:h2, :]]\n","    titles = [\"Low Resolution\", \"Super Resolution\"]\n","    if not testing:\n","      ims.append(hr_im[w0:w1, h1:h2, :])\n","      titles.append('High Resolution')\n","\n","    # Initialize figure and axes\n","    fig, axs = plt.subplots(1,2) if testing else plt.subplots(1,3)\n","    \n","    # show image in each subplot, set title deactivate axis\n","    for idx, ax in enumerate(ims):\n","      axs[idx].imshow(ax)\n","      axs[idx].set_title(titles[idx], fontsize=36)\n","      axs[idx].axis('off')\n","\n","    # Set size and save figure\n","    fig.set_size_inches((40, 40), forward=False)\n","    fig.savefig(f\"figures/test_{im}.png\", bbox_inches='tight')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["42ipoOxnxMDa","osNBARtpxMDc","CB3dlJtBxMDf","aAv7qG5RxMDh","rzKxaMAxxMDn","IvdhMNQuxMDr","bFmJKuvyxMDs","CgMxkPJ6xMDt","WnPpRqrnxMDu","JhXfglv1xMDv","XRUeIpZ-xMDw","rvLjCHl2xMDw","_uUvJJvlxMDx"],"name":"srgan.ipynb","provenance":[]},"interpreter":{"hash":"2018421ac86191517594f147876dbf7cc1c30e03728eafb7def7b7c31a8e41ae"},"kernelspec":{"display_name":"Python 3.8.10 64-bit ('.venv_srgan': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
